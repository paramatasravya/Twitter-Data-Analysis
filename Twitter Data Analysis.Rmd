---
title: "R Notebook"
output: html_notebook
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
# install.packages("tm")
# install.packages("rlist")
# install.packages("tidyverse")
# install.packages("ggplot2")
# install.packages("SnowballC")
# install.packages("gganimate")
# install.packages("tidytext")
# install.packages("igraph")
# install.packages("ggraph")
```


```{r import_libraries}
library(tm)
library(dplyr)
library(rlist)
library(tidyverse)
library(tidytext)
library(SnowballC)
library(ggplot2)
library(gganimate)
library(igraph)
library(ggraph)
```


```{r clean_corpus}
generateCleanCorpusData <- function(input_df) {
  corpus_data <- Corpus(VectorSource(input_df$tweet))
  # Create a Text Mining Map of the input data and convert all words to lower case
  corpus_data <- tm_map(corpus_data, content_transformer(tolower))
  # Remove "’"
  corpus_data <- tm_map(corpus_data, removeWords, c("’"))
  # Remove Emojis
  removeEmojis <- function(x) gsub("[^\x01-\x7F]", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeEmojis))
  # Remove any tagged words
  removeTagWords <- function(x) gsub("@\\S+", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeTagWords))
  # Remove any hash words
  removeHashWords <- function(x) gsub("#\\S+", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeHashWords))
  # Remove Punctuation from the tweets
  corpus_data <- tm_map(corpus_data, removePunctuation)
  # Remove Numerical values from the tweets
  corpus_data <- tm_map(corpus_data, removeNumbers)
  # Remove HTTP links from the tweets
  removeHTTPLinks <- function(x) gsub("http[[:alnum:]]*", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeHTTPLinks))
  # Remove HTTPS links from the tweets
  removeHTTPSLinks <- function(x) gsub("https[[:alnum:]]*", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeHTTPSLinks))
  # Remove english common stop words using tm.stopwords along with any custom stop words
  myStopwords <- c(stopwords(kind = "en"), "tesla", "spacec", "spacex", "s", "amp")
  corpus_data <- tm_map(corpus_data, removeWords, myStopwords)
  # Remove Others
  removeOthers <- function(x) gsub("&amp", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeOthers))
  removeOthers1 <- function(x) gsub("(RT|via)((?:\\b\\W*@\\w+)+)", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeOthers1))
  # Remove empty lines
  removeEmptyLines <- function(x) gsub("^\\s+|\\s+$", "", x)
  corpus_data <- tm_map(corpus_data, content_transformer(removeEmptyLines))
  corpus_data <- corpus_data[sapply(corpus_data, nchar) > 0]
  # Text stemming - Generating a stem Document using SnowballC
  corpus_data <- tm_map(corpus_data, stemDocument, "english")
  return(corpus_data)
}
```

```{r test_code}
generateZipsPlot <- function(input_df) {
  # Generate a Clean Corpus
  myCorpus <- generateCleanCorpusData(input_df)
  # Generate a Frequency Dataframe
  frequency_df <- generateFrequencyDataframe(myCorpus)
  # Sort the dataframe based on frequency
  frequency_df <- frequency_df[with(frequency_df, order(-freq, term)), ]
  # counting the total number of rows
  total_count = nrow(frequency_df)
  # Calculating term frequency
  freq_by_rank <- frequency_df %>% mutate(rank = row_number(), `term frequency` = freq/total)
  # Printing the Coefficients
  print(lm(log10(`term frequency`) ~ log10(rank), data = freq_by_rank))
  # Plotting a Log-Log Plot of the data
  freq_by_rank %>% 
    ggplot(aes(rank, `term frequency`)) + 
    geom_abline(intercept = -0.62, slope = -1.1, color = "gray50", linetype = 2) +
    geom_line(size = 0.5, alpha = 1, show.legend = FALSE) + 
    scale_x_log10() +
    scale_y_log10()
}


input_df <- read.csv("2017.csv")
# Creating a column for year to filter the year wise data
input_df$year <- substr(input_df$date, 1,4)
# Filtering data from only specific year
input_df <- input_df[input_df$year == "2017", ]
generateZipsPlot(input_df)

```
```{r}
myCorpus <- generateCleanCorpusData(input_df)

frequency_df <- generateFrequencyDataframe(myCorpus)
word17 <- frequency_df[with(frequency_df, order(-freq, term)), ]

total=nrow(word17)
total

freqbyrank <- word17 %>% 
  mutate(rank = row_number(), 
         `term frequency` = freq/total) 
 

freqbyrank %>% 
  ggplot(aes(rank, `term frequency`)) + 
  geom_line(size = .5, alpha = 1, show.legend = FALSE) + 
  scale_x_log10() +
  scale_y_log10()

lm(log10(`term frequency`) ~ log10(rank), data = freqbyrank)


freqbyrank %>% 
  ggplot(aes(rank, `term frequency`)) + 
  geom_abline(intercept = -0.62, slope = -1.1,       
              color = "gray5", linetype = 2) +
  geom_line(size = .5, alpha = 1, show.legend = TRUE) + 
  scale_x_log10() +
  scale_y_log10()
```


```{r generate_frequencies}
generateFrequencyDataframe <- function(corpus_data){
  tdm <- TermDocumentMatrix(corpus_data, control = list(wordLengths = c(1, Inf)))
  term.freq <- rowSums(as.matrix(tdm))
  term.freq <- subset(term.freq, term.freq >=1)
  frequency_df <- data.frame(term = names(term.freq), freq = term.freq)
  frequency_df <- frequency_df[with(frequency_df, order(-freq)), ]
  return(frequency_df)
}
```


```{r Zipfs Law and Log-Log Plot}
generateReports <- function(input_df) {
  myCorpus <- generateCleanCorpusData(input_df)
  for (i in 1:10) {
    cat(paste("[[", i, "]] ", sep = ""))
    writeLines(as.character(myCorpus[[i]]))
  }
  frequency_df <- generateFrequencyDataframe(myCorpus)
  frequency_df <- frequency_df[with(frequency_df, order(-freq, term)), ]
  
  # Getting the top 10 frequent words
  top_10_words <- frequency_df[1:10,]
  print(top_10_words)
  
  # Calculating the Rank of the Words vs Frequency Dataframe
  ranked_df <- frequency_df
  ranked_df$rank = 1:nrow(ranked_df)
  
  # Print Ranked Dataframe
  print(ranked_df)
  
  # Plot Words vs Frequency Graphs
  print(ggplot(top_10_words, aes(x=reorder(term, -freq), y=freq, fill = term)) + geom_col() + xlab("Words") + ylab("Frequency"))
  
  # Plot Rank vs Frequency Graphs
  plot(ranked_df$rank, ranked_df$freq, xlab= "Rank", ylab="Frequency", main="Word Distribution")
  
  # Creating Labels for Zipf's Law
  x <- log(ranked_df$rank)
  y <- log(ranked_df$freq)
  # Plotting Zipf's Law
  plot(x, y, xlab = "log(Rank)", ylab = "log(Frequency)", main = "Zipf's Law")
  
  # Creating Labels for Log-Log Plot
  df_log <- data.frame(x=log(ranked_df$rank),
                       y=log(ranked_df$freq))
  # Plotting the Log-Log Plot
  ggplot(df_log, aes(x=x, y=y)) +
    geom_point() +
    labs(title='Log-Log Plot', x='Log(x)', y='Log(y)') +
    theme_minimal()
}
```


```{r BiGram_Network_Graph}
generateBiGramGraph <- function(input_data, filter_value) {
  bigram_corpus <- generateCleanCorpusData(input_data)
  # Create a dataframe from corpus
  bigram_corpus_df <- data.frame(text = sapply(bigram_corpus, as.character), stringsAsFactors = FALSE)
  # Count the Bigrams Word Counts
  count_bigrams <- function(dataset) {
    dataset %>%
      unnest_tokens(bigram, text, token = "ngrams", n = 2) %>%
      separate(bigram, c("word1", "word2"), sep = " ") %>%
      filter(!is.na(word1), !is.na(word2)) %>%
      count(word1, word2, sort = TRUE)
  }
  # Function to Visualize the Bigram Network Graph
  visualize_bigrams <- function(bigram_counts) {
    myvars <- c("word1", "word2","n")
    bigram_tograph <- bigram_counts[myvars]
    # Filtering the word counts whose frequency is greater than 10
    bigram_graph <- bigram_tograph %>% filter(n > filter_value) %>% graph_from_data_frame()
    # Plotting the graph using ggraph library
    ggraph(bigram_graph, layout = "fr") + 
      geom_edge_link(aes(width = n, edge_alpha = n), show.legend = FALSE, edge_colour = "white") +  
      geom_node_point(color = "black", size = 1) + 
      scale_size(range = c(2, 10)) +
      geom_node_text(aes(label = name, family = "mono"), size = 4, vjust = 2, hjust = 2,  repel = TRUE, col = "#EEBA30", check_overlap = TRUE) +  
      labs(title = "Tweet Data", subtitle = "BiGram") + 
      theme(panel.background = element_rect(fill = "black", colour = "black"), plot.background = element_rect(fill = "black"), plot.title = element_text(colour = "white", size = 15, hjust = 0.5, lineheight = 0.9), plot.subtitle = element_text(colour = "white", size = 14,hjust = 0.5), plot.caption = element_text(colour = "white", hjust = 0.5, size = 10))
  }
  # Creating Bigrams Data from the corpus dataframe
  input_data_bigrams <- bigram_corpus_df %>% count_bigrams()
  print(input_data_bigrams)
  visualize_bigrams(input_data_bigrams)
}
```


```{r setcwd}
setwd("/Users/k0t02sr/Documents/Sravya/Assignments/OR/data/")
```


```{r 2017}
input_df <- read.csv("2017.csv")
# Creating a column for year to filter the year wise data
input_df$year <- substr(input_df$date, 1,4)
# Filtering data from only specific year
input_df <- input_df[input_df$year == "2017", ]
# Generate Plots and Bigrams
generateReports(input_df)
generateBiGramGraph(input_df, 10)
```


```{r 2018}
input_df <- read.csv("2018.csv")
# Creating a column for year to filter the year wise data
input_df$year <- substr(input_df$date, 1,4)
# Filtering data from only specific year
input_df <- input_df[input_df$year == "2018", ]
# Generate Plots and Bigrams
generateReports(input_df)
generateBiGramGraph(input_df, 10)
```


```{r 2019}
input_df <- read.csv("2019.csv")
# Creating a column for year to filter the year wise data
input_df$year <- substr(input_df$date, 1,4)
# Filtering data from only specific year
input_df <- input_df[input_df$year == "2019", ]
# Generate Plots and Bigrams
generateReports(input_df)
generateBiGramGraph(input_df, 10)
```


```{r 2020}
input_df <- read.csv("2020.csv")
# Creating a column for year to filter the year wise data
input_df$year <- substr(input_df$date, 1,4)
# Filtering data from only specific year
input_df <- input_df[input_df$year == "2020", ]
# Generate Plots and Bigrams
generateReports(input_df)
generateBiGramGraph(input_df, 10)
```


```{r 2021}
input_df <- read.csv("2021.csv")
# Creating a column for year to filter the year wise data
input_df$year <- substr(input_df$date, 1,4)
# Filtering data from only specific year
input_df <- input_df[input_df$year == "2021", ]
# Generate Plots and Bigrams
generateReports(input_df)
generateBiGramGraph(input_df, 3)
```
